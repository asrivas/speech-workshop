{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bad5f0b-6b6c-40c2-85b3-4207c856acd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4da9994-1423-4c75-99ee-cd81c76714fd",
   "metadata": {},
   "source": [
    "# Cloud Speech Transcription and Content Classification Tutorial\n",
    "\n",
    "This notebook takes you through how to transcribe and analyze sample files. This uses the Speech-to-Text API for converting audio to text and the Natural Language API\n",
    "which provides insights for unstructured text data. After getting started with transcription, will assign a content category for a sample audio file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ef2f66-8a01-4440-92cd-291c7e10adf1",
   "metadata": {},
   "source": [
    "<a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/asrivas/speech-workshop/main/index.ipynb\">\n",
    "Open in Vertex AI Workbench\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf20099-b6cb-42e1-8681-5a562c0a2786",
   "metadata": {},
   "source": [
    "## Part 1: Getting Started with the Speech-to-Text API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897c8c9d-a4eb-4627-8ab4-b60c7e9af356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable the Speech-to-Text API in this Google Cloud project\n",
    "!gcloud services enable speech.googleapis.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb138ee-41dc-4096-9f75-f031a7c8a5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import speech_v1 as speech\n",
    "\n",
    "\n",
    "speech_client = speech.SpeechClient()\n",
    "\n",
    "def speech_to_text_sync(audio):\n",
    "    \"\"\"\n",
    "    Transcribes the audio input.\n",
    "\n",
    "    Args:\n",
    "      audio The location of the audio file.\n",
    "    \"\"\"   \n",
    "    config = dict(language_code=\"en-US\")\n",
    "    response = speech_client.recognize(config=config, audio=audio)\n",
    "    return response\n",
    "\n",
    "def print_output(response):\n",
    "    \"\"\"Prints the transcript and confidence score from a Recognize response object.\"\"\"\n",
    "    \n",
    "    # Each result is for a consecutive portion of the audio. Iterate through\n",
    "    # them to get the transcripts for the entire audio file.\n",
    "    for result in response.results:\n",
    "        best_alternative = result.alternatives[0]\n",
    "        transcript = best_alternative.transcript\n",
    "        confidence = best_alternative.confidence\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"Transcript: {transcript}\")\n",
    "        print(f\"Confidence: {confidence:.0%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00535bc5-a5d1-4ce1-bfc8-4945f2ee4e4a",
   "metadata": {},
   "source": [
    "### Run a sample audio file\n",
    "\n",
    "The sample audio file is stored in a public Google Cloud Storage bucket, to listen to the audio yourself, navigate to the [preview URL](https://storage.googleapis.com/cloud-samples-data/speech/brooklyn_bridge.flac)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa77691f-1890-4c54-880a-52f26123398c",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = dict(uri=\"gs://cloud-samples-data/speech/brooklyn_bridge.flac\")\n",
    "response = speech_to_text_sync(audio)\n",
    "print_output(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16eb0fd-262f-4c0b-8389-d8815777857d",
   "metadata": {},
   "source": [
    "## Part 2: Asynchronous Transcription with Google Cloud Storage\n",
    "\n",
    "In this section we will transcribe a longer audio file. If your file is longer than 60 seconds, the asynchronous endpoint must be used with the data in GCS.\n",
    "\n",
    "Our test file is the first 2 minutes of [episode 328](https://www.gcppodcast.com/post/episode-328-database-migration-service-w-shachar-guz-inna-weiner-gabe-weiss/) of the Google Cloud Podcast discussing the [Database Migration Service](https://cloud.google.com/database-migration).\n",
    "The sample audio file is stored in a public Google Cloud Storage bucket, to listen to the audio yourself, navigate to the [preview URL](https://storage.googleapis.com/cloud-samples-data/speech/sample-podcasts/GCPEpisode328-DatabaseMigrationService-2min%20sample.flac)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a222a07-cde7-41a1-b80d-ee7e2ef2d960",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_to_text_async(audio):\n",
    "    \"\"\"\n",
    "    Transcribes the audio input which must be stored in GCS.\n",
    "\n",
    "    Args:\n",
    "      audio The location of the audio file.\n",
    "    \"\"\"\n",
    "    config = dict(language_code=\"en-US\", audio_channel_count=2, enable_automatic_punctuation=True, model=\"latest_long\")\n",
    "    long_running_recognize_request = speech.types.LongRunningRecognizeRequest(audio=audio, config=config)\n",
    "    print(\"Waiting for operation to complete...\\n\")\n",
    "    operation = speech_client.long_running_recognize(long_running_recognize_request)\n",
    "    response = operation.result(timeout=180) # timeout is in seconds\n",
    "    return response\n",
    "\n",
    "def get_full_transcription(response):\n",
    "    \"\"\"Returns the combined transcription segments\"\"\"\n",
    "    full_text = \"\"\n",
    "    # Each result is for a consecutive portion of the audio. Iterate through\n",
    "    # them to get the transcripts for the entire audio file.\n",
    "    for result in response.results:\n",
    "        best_alternative = result.alternatives[0]\n",
    "        transcript = best_alternative.transcript\n",
    "        full_text += (f\"{transcript}\\n\")\n",
    "    return full_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc98efb-f4e3-40f2-81ee-3b103776440c",
   "metadata": {},
   "source": [
    "### Run a sample audio file\n",
    "\n",
    "While this is running you can enable the [Natural Language API](https://console.cloud.google.com/marketplace/product/google/language.googleapis.com) for the next section, the transcription may take a couple of minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2229a371-e395-4fc3-b83f-936b79788868",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = dict(uri=\"gs://cloud-samples-data/speech/sample-podcasts/GCPEpisode328-DatabaseMigrationService-2min sample.flac\")\n",
    "response = speech_to_text_async(audio)\n",
    "full_text = get_full_transcription(response)\n",
    "print(f\"Transcript:\\n {full_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71956fe2-4ebc-4379-9c3a-38dae00a8265",
   "metadata": {},
   "source": [
    "## Part 3: Analyze Results with the Cloud Natural Language API\n",
    "\n",
    "In this section we will use the output text to classify the content using the Cloud Natural Language Content Classification [feature](https://cloud.google.com/natural-language/docs/classifying-text)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a673df4b-eb7a-4fc0-a2ec-938f9921e56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable the Natural Language API in this Google Cloud project\n",
    "!gcloud services enable language.googleapis.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefd0504-010a-4c08-94f9-eb3d9d618efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import language_v1\n",
    "\n",
    "\n",
    "language_client = language_v1.LanguageServiceClient()\n",
    "\n",
    "def classify_text(text_content):\n",
    "    \"\"\"\n",
    "    Classifying Content in a String and prints the categories.\n",
    "\n",
    "    Args:\n",
    "      text_content The text content to analyze.\n",
    "    \"\"\"\n",
    "\n",
    "    # Available types: PLAIN_TEXT, HTML\n",
    "    type_ = language_v1.Document.Type.PLAIN_TEXT\n",
    "\n",
    "    # Optional. If not specified, the language is automatically detected.\n",
    "    # For list of supported languages:\n",
    "    # https://cloud.google.com/natural-language/docs/languages\n",
    "    language = \"en\"\n",
    "    document = {\"content\": text_content, \"type_\": type_, \"language\": language}\n",
    "\n",
    "    content_categories_version = (\n",
    "        language_v1.ClassificationModelOptions.V2Model.ContentCategoriesVersion.V2)\n",
    "    response = language_client.classify_text(request = {\n",
    "        \"document\": document,\n",
    "        \"classification_model_options\": {\n",
    "            \"v2_model\": {\n",
    "                \"content_categories_version\": content_categories_version\n",
    "            }\n",
    "        }\n",
    "    })\n",
    "    # Loop through classified categories returned from the API\n",
    "    for category in response.categories:\n",
    "        # Get the name of the category representing the document.\n",
    "        # See the predefined taxonomy of categories:\n",
    "        # https://cloud.google.com/natural-language/docs/categories\n",
    "        print(u\"Category name: {}\".format(category.name))\n",
    "        # Get the confidence. Number representing how certain the classifier\n",
    "        # is that this category represents the provided text.\n",
    "        print(u\"Confidence: {}\".format(category.confidence))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e58bdd5-41c2-4fa6-86cb-b99e033f1532",
   "metadata": {},
   "source": [
    "### Categorize the sample text\n",
    "\n",
    "This will provide a list of categories from this [list](https://cloud.google.com/natural-language/docs/categories#categories_version_2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28a99d3-38ca-4017-aeda-40cd01e472f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_text(full_text)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m100",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m100"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
